#!/usr/bin/env python3
"""
Cloudflare ä¼˜é€‰IPæå–å™¨
ä» https://api.uouin.com/cloudflare.html ä¸‹è½½å¹¶æå–ä¼˜é€‰IP
ä½¿ç”¨æ— å¤´æµè§ˆå™¨(Pyppeteer)æŠ“å–æ•°æ®
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from pyppeteer import launch
from bs4 import BeautifulSoup


SUCCESS_TEXT = 'CloudFlareä¼˜é€‰IPä»…å¯¹CDNèŠ‚ç‚¹IPè¿›è¡Œä¼˜é€‰ï¼Œä¸æä¾›ä»»ä½•CDNæœåŠ¡ï¼Œä¸¥ç¦ç”¨æˆ·ç”¨äºä»äº‹ä»»ä½•è¿æ³•çŠ¯ç½ªè¡Œä¸ºæˆ–å¸®åŠ©ç½‘ç»œä¿¡æ¯çŠ¯ç½ªè¡Œä¸º'


async def download_html(url: str) -> str:
    """ä½¿ç”¨æ— å¤´æµè§ˆå™¨ä¸‹è½½HTMLå†…å®¹"""
    print(f"æ­£åœ¨ä½¿ç”¨æ— å¤´æµè§ˆå™¨è®¿é—®: {url}")

    browser = None
    try:
        # æŸ¥æ‰¾æœ¬åœ° Chrome è·¯å¾„
        possible_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
            r"C:\Users\{}\AppData\Local\Google\Chrome\Application\chrome.exe".format(os.getenv('USERNAME', '')),
            os.path.join(os.getenv('LOCALAPPDATA', ''), r"Google\Chrome\Application\chrome.exe"),
            # å°è¯• Edge æµè§ˆå™¨ä½œä¸ºå¤‡é€‰
            r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files\Microsoft\Edge\Application\msedge.exe"
        ]

        executable_path = None
        for path in possible_paths:
            if os.path.exists(path):
                executable_path = path
                break

        if executable_path:
            print(f"âœ“ æ£€æµ‹åˆ°æœ¬åœ°æµè§ˆå™¨: {executable_path}")
        else:
            print("âš  æœªæ£€æµ‹åˆ° Chrome/Edgeï¼Œå°†å°è¯•ä½¿ç”¨ Pyppeteer é»˜è®¤ä¸‹è½½ï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼‰")
            print("æç¤º: å¦‚æœæŠ¥é”™ï¼Œè¯·å®‰è£… Google Chrome æˆ– Microsoft Edge")

        # å¯åŠ¨æ— å¤´æµè§ˆå™¨
        browser = await launch(
            headless=True,
            executablePath=executable_path,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )
        page = await browser.newPage()

        # è®¾ç½®ç”¨æˆ·ä»£ç†ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

        # éšè—webdriverç‰¹å¾
        await page.evaluateOnNewDocument('''() => {
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            Object.defineProperty(navigator, 'languages', {get: () => ['zh-CN', 'zh', 'en']});
        }''')

        # è®¿é—®ç›®æ ‡é¡µé¢ï¼Œç­‰å¾…ç½‘ç»œç©ºé—²
        await page.goto(url, {
            'waitUntil': 'networkidle2',
            'timeout': 60000
        })

        # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        await asyncio.sleep(3)

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½
        page_content = await page.content()
        if SUCCESS_TEXT in page_content:
            print("âœ“ æ•°æ®åŠ è½½æˆåŠŸ!")
        else:
            print("âš  è­¦å‘Š: æœªæ£€æµ‹åˆ°æˆåŠŸåŠ è½½æ ‡è¯†æ–‡æœ¬")

        return page_content

    except Exception as e:
        print(f"æµè§ˆå™¨è®¿é—®å¤±è´¥: {e}")
        sys.exit(1)
    finally:
        if browser:
            await browser.close()


def extract_ips(html: str) -> list:
    """ä»HTMLä¸­æå–IPåœ°å€"""
    soup = BeautifulSoup(html, 'html.parser')
    results = []

    table = soup.find('table')
    if not table:
        print("æœªæ‰¾åˆ°è¡¨æ ¼")
        return results

    tbody = table.find('tbody')
    if not tbody:
        print("æœªæ‰¾åˆ°tbody")
        return results

    rows = tbody.find_all('tr')
    valid_isps = ['ç”µä¿¡', 'è”é€š', 'ç§»åŠ¨', 'å¤šçº¿', 'IPV6']

    for row in rows:
        cells = row.find_all(['td', 'th'])
        # è¡¨æ ¼ç»“æ„: #, çº¿è·¯, ä¼˜é€‰IP, ä¸¢åŒ…, å»¶è¿Ÿ, é€Ÿåº¦, å¸¦å®½, Colo, æ—¶é—´
        if len(cells) >= 9:
            isp = cells[1].get_text(strip=True)
            ip = cells[2].get_text(strip=True)
            time = cells[8].get_text(strip=True)  # æœ€åä¸€åˆ—æ˜¯æ—¶é—´

            if isp in valid_isps and ip:
                results.append({
                    'isp': isp,
                    'ip': ip,
                    'time': time
                })

    return results


def print_summary(results: list):
    """æ‰“å°æå–æ‘˜è¦"""
    isps = {}
    for item in results:
        isp = item['isp']
        isps[isp] = isps.get(isp, 0) + 1

    print("\n=== æå–ç»“æœ ===")
    print(f"æ€»è®¡: {len(results)} ä¸ªIP")
    for isp, count in isps.items():
        print(f"  {isp}: {count}ä¸ª")


def load_existing_data(output_file: str) -> list:
    """åŠ è½½ç°æœ‰æ•°æ®"""
    if not os.path.exists(output_file):
        return []

    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
            return existing_data.get('data', [])
    except Exception as e:
        print(f"âš  åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return []


def merge_and_deduplicate(existing_data: list, new_data: list) -> list:
    """åˆå¹¶æ–°æ—§æ•°æ®å¹¶æŒ‰IPå»é‡"""
    # åˆ›å»ºIPåˆ°æ•°æ®çš„æ˜ å°„ï¼Œæ–°æ•°æ®ä¼˜å…ˆ
    ip_map = {}

    # å…ˆæ·»åŠ æ—§æ•°æ®
    for item in existing_data:
        ip = item.get('ip')
        if ip:
            ip_map[ip] = item

    # ç”¨æ–°æ•°æ®è¦†ç›–ï¼ˆæ–°æ•°æ®ä¼˜å…ˆï¼‰
    for item in new_data:
        ip = item.get('ip')
        if ip:
            ip_map[ip] = item

    # è¿”å›åˆå¹¶åçš„åˆ—è¡¨
    return list(ip_map.values())


async def main():
    url = "https://api.uouin.com/cloudflare.html"
    output_file = "cloudflare_ips.json"

    # ä¸‹è½½HTML
    html = await download_html(url)

    # æå–IP
    new_results = extract_ips(html)

    # åŠ è½½ç°æœ‰æ•°æ®
    existing_results = load_existing_data(output_file)
    print(f"ğŸ“‚ ç°æœ‰æ•°æ®: {len(existing_results)} æ¡")

    # åˆå¹¶å¹¶å»é‡
    merged_results = merge_and_deduplicate(existing_results, new_results)

    # æ‰“å°æ‘˜è¦
    print("\n=== æ–°æå–æ•°æ® ===")
    print(f"æ–°å¢: {len(new_results)} ä¸ªIP")

    print_summary(merged_results)

    # æ·»åŠ æ—¶é—´æˆ³
    output_data = {
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_count": len(merged_results),
        "data": merged_results
    }

    # è¾“å‡ºJSON
    json_output = json.dumps(output_data, ensure_ascii=False, indent=2)
    print("\n=== JSONè¾“å‡º ===")
    print(json_output)

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(json_output)
    print(f"\nâœ“ å·²ä¿å­˜åˆ°: {output_file}")
    print(f"âœ“ æ€»è®°å½•æ•°: {len(merged_results)} (åŸæœ‰: {len(existing_results)}, æ–°å¢: {len(new_results)})")


if __name__ == "__main__":
    # Windowsç³»ç»Ÿä¸‹è§£å†³ asyncio äº‹ä»¶å¾ªç¯ç­–ç•¥é—®é¢˜
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    asyncio.run(main())
